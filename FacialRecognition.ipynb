{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf142a2-cc78-4f46-85e5-c3b6051b392d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "print('asdas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5f6e98ba-3dee-4e29-a28e-7476c9a980c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.layers import Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4effc63-6193-46f0-a66d-fc5baf5ecd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths and parameters\n",
    "data_dir = './CelebA'\n",
    "image_dir = os.path.join(data_dir, 'img_align_celeba')\n",
    "anno_path = os.path.join(data_dir, 'list_attr_celeba.txt')\n",
    "image_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffe88685-c1a7-452f-8a20-43110c89bc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load annotations\n",
    "df = pd.read_csv(anno_path, sep=' ', skipinitialspace=True)\n",
    "df = df.replace(to_replace=-1, value=0)  # replace -1 with 0\n",
    "df = df.sample(frac=1).reset_index(drop=True)  # shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f050e0f4-faca-420d-93c1-41cd1788fe8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b6895eb-b726-48c1-9a2b-6fbfcd880e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define helper functions\n",
    "def load_image(image_path):\n",
    "    img = Image.open(image_path)\n",
    "    img = img.convert('RGB')\n",
    "    img = img.resize((image_size, image_size))\n",
    "    return img\n",
    "\n",
    "\n",
    "def preprocess_data(df):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i, row in df.iterrows():\n",
    "        image_path = os.path.join(image_dir, f\"{row.name}.jpg\")\n",
    "        try:\n",
    "            img = load_image(image_path)\n",
    "        except: \n",
    "            continue\n",
    "        X.append(np.array(img))\n",
    "        y.append(row[1:])\n",
    "    X = np.array(X) / 255.0  # normalize pixel values\n",
    "    y = np.array(y)\n",
    "    return X, y\n",
    "\n",
    "# Preprocess data\n",
    "X_train, y_train = preprocess_data(train_df)\n",
    "X_test, y_test = preprocess_data(test_df)\n",
    "\n",
    "num_classes = y_train.shape[1]\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c99a19ef-4436-49da-b4b9-b43adbc93675",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "# Construct the model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(64,64,3)),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    Flatten(),\n",
    "])\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1521, activation='sigmoid'))\n",
    "model.add(Reshape((39, 39)))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "46035966-14e3-4ca7-8938-6ac85353447c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_18 (Conv2D)          (None, 62, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 31, 31, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 29, 29, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 14, 14, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 12, 12, 64)        36928     \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 9216)              0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 256)               2359552   \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1521)              390897    \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 39, 39)            0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,806,769\n",
      "Trainable params: 2,806,769\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "(20576, 39, 39)\n",
      "(82023, 39, 39)\n",
      "(20576, 64, 64, 3)\n",
      "(82023, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())\n",
    "print(y_test.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "71594f5c-1d3c-4853-a50b-a617d8c47c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1282/1282 [==============================] - 47s 35ms/step - loss: 0.4835 - accuracy: 0.7958 - val_loss: 0.4316 - val_accuracy: 0.8020\n",
      "Epoch 2/10\n",
      "1282/1282 [==============================] - 37s 29ms/step - loss: 0.4294 - accuracy: 0.8033 - val_loss: 0.4309 - val_accuracy: 0.8020\n",
      "Epoch 3/10\n",
      "1282/1282 [==============================] - 37s 29ms/step - loss: 0.4292 - accuracy: 0.8033 - val_loss: 0.4308 - val_accuracy: 0.8020\n",
      "Epoch 4/10\n",
      "1282/1282 [==============================] - 37s 29ms/step - loss: 0.4291 - accuracy: 0.8033 - val_loss: 0.4306 - val_accuracy: 0.8020\n",
      "Epoch 5/10\n",
      "1282/1282 [==============================] - 37s 29ms/step - loss: 0.4291 - accuracy: 0.8033 - val_loss: 0.4307 - val_accuracy: 0.8020\n",
      "Epoch 6/10\n",
      "1282/1282 [==============================] - 36s 28ms/step - loss: 0.4290 - accuracy: 0.8033 - val_loss: 0.4306 - val_accuracy: 0.8020\n",
      "Epoch 7/10\n",
      "1282/1282 [==============================] - 36s 28ms/step - loss: 0.4290 - accuracy: 0.8033 - val_loss: 0.4307 - val_accuracy: 0.8020\n",
      "Epoch 8/10\n",
      "1282/1282 [==============================] - 36s 28ms/step - loss: 0.4290 - accuracy: 0.8033 - val_loss: 0.4307 - val_accuracy: 0.8020\n",
      "Epoch 9/10\n",
      "1282/1282 [==============================] - 36s 28ms/step - loss: 0.4290 - accuracy: 0.8033 - val_loss: 0.4306 - val_accuracy: 0.8020\n",
      "Epoch 10/10\n",
      "1282/1282 [==============================] - 36s 28ms/step - loss: 0.4290 - accuracy: 0.8033 - val_loss: 0.4306 - val_accuracy: 0.8020\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "from keras.callbacks import CSVLogger\n",
    "\n",
    "csv_logger = CSVLogger('log.csv', append=True, separator=';')\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=64,\n",
    "                    epochs=10,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    callbacks=[csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dcd9f7ac-8c9c-4d5e-a582-1d8b07ef4c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "643/643 [==============================] - 6s 10ms/step - loss: 0.4306 - accuracy: 0.8020\n",
      "Test accuracy: 0.8019599914550781\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [82023, 20576]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m test_loss, test_acc \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest accuracy:\u001b[39m\u001b[38;5;124m'\u001b[39m, test_acc)\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mrecall_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniforge3/envs/tensorflow_silicon/lib/python3.9/site-packages/sklearn/metrics/_classification.py:2098\u001b[0m, in \u001b[0;36mrecall_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1967\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrecall_score\u001b[39m(\n\u001b[1;32m   1968\u001b[0m     y_true,\n\u001b[1;32m   1969\u001b[0m     y_pred,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1975\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1976\u001b[0m ):\n\u001b[1;32m   1977\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the recall.\u001b[39;00m\n\u001b[1;32m   1978\u001b[0m \n\u001b[1;32m   1979\u001b[0m \u001b[38;5;124;03m    The recall is the ratio ``tp / (tp + fn)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2096\u001b[0m \u001b[38;5;124;03m    array([1. , 1. , 0.5])\u001b[39;00m\n\u001b[1;32m   2097\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2098\u001b[0m     _, r, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mprecision_recall_fscore_support\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2099\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2100\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2101\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2103\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2104\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwarn_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrecall\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2105\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2106\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2107\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "File \u001b[0;32m~/miniforge3/envs/tensorflow_silicon/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1573\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m beta \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1572\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbeta should be >=0 in the F-beta score\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1573\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43m_check_set_wise_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1575\u001b[0m \u001b[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[1;32m   1576\u001b[0m samplewise \u001b[38;5;241m=\u001b[39m average \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/envs/tensorflow_silicon/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1374\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m average \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m average_options \u001b[38;5;129;01mand\u001b[39;00m average \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1372\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maverage has to be one of \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(average_options))\n\u001b[0;32m-> 1374\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1375\u001b[0m \u001b[38;5;66;03m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[39;00m\n\u001b[1;32m   1376\u001b[0m \u001b[38;5;66;03m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[39;00m\n\u001b[1;32m   1377\u001b[0m present_labels \u001b[38;5;241m=\u001b[39m unique_labels(y_true, y_pred)\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[0;32m~/miniforge3/envs/tensorflow_silicon/lib/python3.9/site-packages/sklearn/metrics/_classification.py:86\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[1;32m     60\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \n\u001b[1;32m     62\u001b[0m \u001b[38;5;124;03m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;124;03m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m     \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m     type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     88\u001b[0m     type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/tensorflow_silicon/lib/python3.9/site-packages/sklearn/utils/validation.py:397\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    395\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 397\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    398\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    399\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    400\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [82023, 20576]"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "from sklearn.metrics import recall_score, f1_score\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', test_acc)\n",
    "print('recall', recall_score(y_train,y_test))\n",
    "print('f1_score', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83954494-4315-4b27-8655-a077297d5af9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
